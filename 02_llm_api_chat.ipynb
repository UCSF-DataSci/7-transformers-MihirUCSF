{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27a6b19",
   "metadata": {},
   "source": [
    "# Part 2: Basic LLM Chat Tool\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this part, you'll create a simple command-line chat tool that interacts with a Large Language Model (LLM) through the Hugging Face API. This tool will allow you to have conversations with an LLM about healthcare topics.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Connect to the Hugging Face API\n",
    "- Create a basic interactive chat loop\n",
    "- Handle simple error cases\n",
    "- Test with healthcare questions\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: tensorflow>=2.8.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 10)) (2.19.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.7.0)\n",
      "Requirement already satisfied: transformers>=4.18.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 12)) (4.51.3)\n",
      "Requirement already satisfied: requests>=2.27.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 15)) (2.32.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.5.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 16)) (0.31.2)\n",
      "Requirement already satisfied: accelerate>=0.12.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 17)) (1.7.0)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 18)) (0.2.0)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 19)) (0.21.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 22)) (3.6.0)\n",
      "Requirement already satisfied: regex>=2022.3.15 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 23)) (2024.11.6)\n",
      "Requirement already satisfied: plotly>=5.6.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 26)) (6.1.0)\n",
      "Requirement already satisfied: wandb>=0.12.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 29)) (0.19.11)\n",
      "Requirement already satisfied: pytest>=7.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 30)) (8.3.5)\n",
      "Requirement already satisfied: jupytext>=1.13.8 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from -r requirements.txt (line 31)) (1.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tqdm>=4.62.0->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (5.29.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (80.7.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from transformers>=4.18.0->-r requirements.txt (line 12)) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from transformers>=4.18.0->-r requirements.txt (line 12)) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (2025.4.26)\n",
      "Requirement already satisfied: psutil in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from accelerate>=0.12.0->-r requirements.txt (line 17)) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (0.70.16)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from plotly>=5.6.0->-r requirements.txt (line 26)) (1.39.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (8.2.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (4.3.8)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (2.11.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (2.28.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (1.3.6)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pytest>=7.0.0->-r requirements.txt (line 30)) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pytest>=7.0.0->-r requirements.txt (line 30)) (1.6.0)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (0.4.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (5.10.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.45.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (3.11.18)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.12.0->-r requirements.txt (line 29)) (4.0.12)\n",
      "Requirement already satisfied: rich in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from markdown-it-py>=1.0->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.10.0->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jinja2->torch>=1.10.0->-r requirements.txt (line 11)) (3.0.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (5.14.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.20.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.12.0->-r requirements.txt (line 29)) (5.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.25.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (310)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mihir\\onedrive\\desktop\\datasci223\\7-transformers-mihirucsf\\venv\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key successfully set in environment variables\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Additional packages for LLM API interaction\n",
    "%pip install requests\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "from typing import Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('utils', exist_ok=True)\n",
    "os.makedirs('results/part_2', exist_ok=True)\n",
    "\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"API key successfully set in environment variables\")\n",
    "else:\n",
    "    print(\"Failed to set API key in environment\")\n",
    "\n",
    "# Create headers for API requests\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd4651",
   "metadata": {},
   "source": [
    "## 1. Connecting to the Hugging Face API\n",
    "\n",
    "The Hugging Face Inference API provides access to many language models. We'll use models that are available on the free tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf654be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending test query...\n",
      "API Response:\n",
      "[{'summary_text': 'CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Visit CNN.com/Travel each week for a new gallery of snapshots. This week, we feature snapshots from the U.S. and Canada. See www.dailymail.co.uk/Travel.'}]\n"
     ]
    }
   ],
   "source": [
    "# Example of a simple API request to Hugging Face\n",
    "API_URL = API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "\n",
    "def query(payload):\n",
    "    try:\n",
    "        # Get API key from environment\n",
    "        api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "        if not api_key:\n",
    "            return {\"error\": \"API key not found in environment variables\"}\n",
    "            \n",
    "        # Set up headers with the API key\n",
    "        headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "        \n",
    "        # Send request to the API\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse and return the JSON response\n",
    "        return response.json()\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API request failed: {e}\")\n",
    "        # Check if we got a response before the exception\n",
    "        if 'response' in locals():\n",
    "            logger.error(f\"Response status code: {response.status_code}\")\n",
    "            logger.error(f\"Response content: {response.text}\")\n",
    "        return {\"error\": str(e)}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    \n",
    "# Test the query function\n",
    "test_payload = {\"inputs\": \"What are the symptoms of diabetes?\"}\n",
    "print(\"Sending test query...\")\n",
    "response = query(test_payload)\n",
    "print(\"API Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e05322",
   "metadata": {},
   "source": [
    "## 2. Creating Simple Chat Scripts\n",
    "\n",
    "Your task is to create two simple scripts that interact with the Hugging Face API:\n",
    "\n",
    "1. A basic one-off chat script (`utils/one_off_chat.py`)\n",
    "2. A contextual conversation script (`utils/conversation.py`)\n",
    "\n",
    "### One-Off Chat Script\n",
    "\n",
    "Create a script that handles independent interactions (each prompt/response is separate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056ffd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Simple LLM Chat! Type 'exit' to quit.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# utils/one_off_chat.py\n",
    "\n",
    "import requests\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import time  # Added import for sleep\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_response(prompt, model_name=\"facebook/bart-large-cnn\", api_key=None, history=None, history_length=3, max_retries=3):\n",
    "    # Get API key from environment if not provided\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "        if not api_key:\n",
    "            logger.error(\"No API key provided and none found in environment\")\n",
    "            return \"Error: API key is required but none was provided\"\n",
    "    \n",
    "    # Set up the API URL and headers\n",
    "    api_url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    \n",
    "    # Create payload with the prompt\n",
    "    payload = {\"inputs\": prompt}\n",
    "    \n",
    "    # Initialize retry counter and backoff time\n",
    "    retry_count = 0\n",
    "    backoff_time = 1  # Start with 1 second\n",
    "    \n",
    "    while retry_count <= max_retries:\n",
    "        try:\n",
    "            # Send request to the API\n",
    "            response = requests.post(api_url, headers=headers, json=payload)\n",
    "            \n",
    "            # Check for rate limiting\n",
    "            if response.status_code == 429:\n",
    "                retry_count += 1\n",
    "                if retry_count > max_retries:\n",
    "                    logger.warning(f\"Rate limit exceeded after {max_retries} retries\")\n",
    "                    return \"Error: Rate limit exceeded. Please try again later.\"\n",
    "                \n",
    "                # Get retry-after header if available, otherwise use exponential backoff\n",
    "                retry_after = response.headers.get('retry-after')\n",
    "                if retry_after and retry_after.isdigit():\n",
    "                    wait_time = int(retry_after)\n",
    "                else:\n",
    "                    wait_time = backoff_time\n",
    "                    backoff_time *= 2  # Exponential backoff\n",
    "                \n",
    "                logger.info(f\"Rate limited. Retrying in {wait_time} seconds (attempt {retry_count}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue  # Try again\n",
    "            \n",
    "            # For non-rate-limiting errors, raise the exception\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse the response\n",
    "            result = response.json()\n",
    "            \n",
    "            # Extract the generated text from the response - updated to handle BART format\n",
    "            if isinstance(result, list) and len(result) > 0:\n",
    "                if isinstance(result[0], dict):\n",
    "                    # Handle different model response formats\n",
    "                    if \"summary_text\" in result[0]:\n",
    "                        return result[0][\"summary_text\"]\n",
    "                    elif \"generated_text\" in result[0]:\n",
    "                        return result[0][\"generated_text\"]\n",
    "                elif isinstance(result[0], str):\n",
    "                    return result[0]\n",
    "            \n",
    "            # If we get here, the response format wasn't recognized\n",
    "            logger.warning(f\"Unexpected response format: {result}\")\n",
    "            return str(result)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"API request failed: {e}\")\n",
    "            if 'response' in locals():\n",
    "                logger.error(f\"Response status code: {response.status_code}\")\n",
    "                logger.error(f\"Response content: {response.text}\")\n",
    "            \n",
    "            # Check if we should retry based on error type\n",
    "            if isinstance(e, requests.exceptions.ConnectionError) and retry_count < max_retries:\n",
    "                retry_count += 1\n",
    "                wait_time = backoff_time\n",
    "                backoff_time *= 2  # Exponential backoff\n",
    "                logger.info(f\"Connection error. Retrying in {wait_time} seconds (attempt {retry_count}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue  # Try again\n",
    "                \n",
    "            return f\"Error: Failed to get response from the model. {str(e)}\"\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error: {e}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "def run_chat():\n",
    "    \"\"\"Run an interactive chat session\"\"\"\n",
    "    print(\"Welcome to the Simple LLM Chat! Type 'exit' to quit.\")\n",
    "    \n",
    "    # Check if API key is available\n",
    "    api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"Warning: No API key found in environment variables.\")\n",
    "        api_key = input(\"Please enter your Hugging Face API key: \")\n",
    "        if not api_key:\n",
    "            print(\"No API key provided. Exiting.\")\n",
    "            return\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not user_input.strip():\n",
    "            print(\"Bot: Please enter a question or prompt.\")\n",
    "            continue\n",
    "            \n",
    "        # Get response from the model\n",
    "        print(\"Bot: Thinking...\")\n",
    "        response = get_response(user_input, api_key=api_key)\n",
    "        print(f\"Bot: {response}\")\n",
    "        \n",
    "def main():\n",
    "    try:\n",
    "        # Check if we're running in IPython/Jupyter\n",
    "        get_ipython\n",
    "        # We're in a notebook, so don't parse arguments - just run the chat\n",
    "        run_chat()\n",
    "        return\n",
    "    except NameError:\n",
    "        # We're not in a notebook, parse arguments as normal\n",
    "        parser = argparse.ArgumentParser(description=\"Chat with an LLM\")\n",
    "        parser.add_argument(\"--model\", type=str, default=\"facebook/bart-large-cnn\",\n",
    "                          help=\"Model to use (default: facebook/bart-large-cnn)\")\n",
    "        parser.add_argument(\"--key\", type=str, help=\"Hugging Face API key\")\n",
    "        parser.add_argument(\"--prompt\", type=str, help=\"Single prompt (non-interactive mode)\")\n",
    "        parser.add_argument(\"--max-retries\", type=int, default=3,\n",
    "                          help=\"Maximum number of retry attempts for rate limiting (default: 3)\")\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        # If a single prompt is provided, just get the response and exit\n",
    "        if args.prompt:\n",
    "            response = get_response(args.prompt, model_name=args.model, api_key=args.key, max_retries=args.max_retries)\n",
    "            print(f\"Response: {response}\")\n",
    "        else:\n",
    "            # Otherwise, run the interactive chat\n",
    "            run_chat()\n",
    "\n",
    "# Call the main function when running this script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ee348",
   "metadata": {},
   "source": [
    "### Contextual Conversation Script\n",
    "\n",
    "Create a script that maintains conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167adfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Contextual LLM Chat! Type 'exit' to quit.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# utils/conversation.py\n",
    "\n",
    "import requests\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import time  # Added import for sleep\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_response(prompt, history=None, model_name=\"facebook/bart-large-cnn\", api_key=None, history_length=3, max_retries=3):\n",
    "    # Initialize history if None\n",
    "    if history is None:\n",
    "        history = []\n",
    "    \n",
    "    # Get API key from environment if not provided\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "        if not api_key:\n",
    "            logger.error(\"No API key provided and none found in environment\")\n",
    "            return \"Error: API key is required but none was provided\"\n",
    "    \n",
    "    # Set up the API URL and headers\n",
    "    api_url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    \n",
    "    # Format a prompt that includes previous exchanges (limited by history_length)\n",
    "    context = \"\"\n",
    "    if history:\n",
    "        # Take only the most recent exchanges up to history_length\n",
    "        recent_history = history[-history_length:]\n",
    "        for i, (past_prompt, past_response) in enumerate(recent_history):\n",
    "            context += f\"Question {i+1}: {past_prompt}\\nAnswer {i+1}: {past_response}\\n\\n\"\n",
    "    \n",
    "    # Add the current prompt with context\n",
    "    full_prompt = f\"{context}Question: {prompt}\\nAnswer:\"\n",
    "    \n",
    "    # Create payload with the contextual prompt\n",
    "    payload = {\"inputs\": full_prompt}\n",
    "    \n",
    "    # Initialize retry counter and backoff time\n",
    "    retry_count = 0\n",
    "    backoff_time = 1  # Start with 1 second\n",
    "    \n",
    "    while retry_count <= max_retries:\n",
    "        try:\n",
    "            # Send request to the API\n",
    "            response = requests.post(api_url, headers=headers, json=payload)\n",
    "            \n",
    "            # Check for rate limiting\n",
    "            if response.status_code == 429:\n",
    "                retry_count += 1\n",
    "                if retry_count > max_retries:\n",
    "                    logger.warning(f\"Rate limit exceeded after {max_retries} retries\")\n",
    "                    return \"Error: Rate limit exceeded. Please try again later.\"\n",
    "                \n",
    "                # Get retry-after header if available, otherwise use exponential backoff\n",
    "                retry_after = response.headers.get('retry-after')\n",
    "                if retry_after and retry_after.isdigit():\n",
    "                    wait_time = int(retry_after)\n",
    "                else:\n",
    "                    wait_time = backoff_time\n",
    "                    backoff_time *= 2  # Exponential backoff\n",
    "                \n",
    "                logger.info(f\"Rate limited. Retrying in {wait_time} seconds (attempt {retry_count}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue  # Try again\n",
    "            \n",
    "            # For non-rate-limiting errors, raise the exception\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse the response\n",
    "            result = response.json()\n",
    "            \n",
    "            # Extract the generated text from the response - updated to handle BART format\n",
    "            if isinstance(result, list) and len(result) > 0:\n",
    "                if isinstance(result[0], dict):\n",
    "                    # Handle different model response formats\n",
    "                    if \"summary_text\" in result[0]:\n",
    "                        generated_text = result[0][\"summary_text\"]\n",
    "                        # Remove the prompt if it's included in the response\n",
    "                        if full_prompt in generated_text:\n",
    "                            generated_text = generated_text.replace(full_prompt, \"\").strip()\n",
    "                        return generated_text\n",
    "                    elif \"generated_text\" in result[0]:\n",
    "                        generated_text = result[0][\"generated_text\"]\n",
    "                        # Remove the prompt if it's included in the response\n",
    "                        if full_prompt in generated_text:\n",
    "                            generated_text = generated_text.replace(full_prompt, \"\").strip()\n",
    "                        return generated_text\n",
    "                elif isinstance(result[0], str):\n",
    "                    return result[0]\n",
    "            \n",
    "            logger.warning(f\"Unexpected response format: {result}\")\n",
    "            return str(result)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"API request failed: {e}\")\n",
    "            if 'response' in locals():\n",
    "                logger.error(f\"Response status code: {response.status_code}\")\n",
    "                logger.error(f\"Response content: {response.text}\")\n",
    "                \n",
    "            # Check if we should retry based on error type\n",
    "            if isinstance(e, requests.exceptions.ConnectionError) and retry_count < max_retries:\n",
    "                retry_count += 1\n",
    "                wait_time = backoff_time\n",
    "                backoff_time *= 2  # Exponential backoff\n",
    "                logger.info(f\"Connection error. Retrying in {wait_time} seconds (attempt {retry_count}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue  # Try again\n",
    "                \n",
    "            return f\"Error: Failed to get response from the model. {str(e)}\"\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error: {e}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "def run_chat():\n",
    "    \"\"\"Run an interactive chat session with context\"\"\"\n",
    "    print(\"Welcome to the Contextual LLM Chat! Type 'exit' to quit.\")\n",
    "    \n",
    "    # Check if API key is available\n",
    "    api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"Warning: No API key found in environment variables.\")\n",
    "        api_key = input(\"Please enter your Hugging Face API key: \")\n",
    "        if not api_key:\n",
    "            print(\"No API key provided. Exiting.\")\n",
    "            return\n",
    "    \n",
    "    # Initialize conversation history\n",
    "    history = []\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not user_input.strip():\n",
    "            print(\"Bot: Please enter a question or prompt.\")\n",
    "            continue\n",
    "            \n",
    "        # Get response using conversation history\n",
    "        print(\"Bot: Thinking...\")\n",
    "        response = get_response(user_input, history=history, api_key=api_key)\n",
    "        print(f\"Bot: {response}\")\n",
    "        \n",
    "        # Update history with the current exchange\n",
    "        history.append((user_input, response))\n",
    "        \n",
    "def main():\n",
    "    try:\n",
    "        # Check if we're running in IPython/Jupyter\n",
    "        get_ipython\n",
    "        run_chat()\n",
    "        return\n",
    "    except NameError:\n",
    "        # We're not in a notebook, parse arguments as normal\n",
    "        parser = argparse.ArgumentParser(description=\"Chat with an LLM using conversation history\")\n",
    "        parser.add_argument(\"--model\", type=str, default=\"facebook/bart-large-cnn\",\n",
    "                        help=\"Model to use (default: facebook/bart-large-cnn)\")\n",
    "        parser.add_argument(\"--key\", type=str, help=\"Hugging Face API key\")\n",
    "        parser.add_argument(\"--history-length\", type=int, default=3,\n",
    "                        help=\"Number of previous exchanges to include in context (default: 3)\")\n",
    "        parser.add_argument(\"--prompt\", type=str, help=\"Single prompt (non-interactive mode)\")\n",
    "        parser.add_argument(\"--max-retries\", type=int, default=3,\n",
    "                        help=\"Maximum number of retry attempts for rate limiting (default: 3)\")\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        # If a single prompt is provided, just get the response and exit\n",
    "        if args.prompt:\n",
    "            response = get_response(args.prompt, model_name=args.model, api_key=args.key, max_retries=args.max_retries)\n",
    "            print(f\"Response: {response}\")\n",
    "        else:\n",
    "            # Otherwise, run the interactive chat\n",
    "            run_chat()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69492f0c",
   "metadata": {},
   "source": [
    "## 3. Testing and Evaluation\n",
    "\n",
    "Create a script to test your chat implementations with specific healthcare questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfda7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 11:40:12,032 - __main__ - INFO - Running in notebook mode, saving modules...\n",
      "2025-05-19 11:40:12,034 - __main__ - INFO - Using functions from notebook environment\n",
      "2025-05-19 11:40:12,035 - __main__ - INFO - Testing one-off chat...\n",
      "2025-05-19 11:40:12,036 - __main__ - INFO - Testing one-off chat with 5 questions\n",
      "2025-05-19 11:40:12,036 - __main__ - INFO - Testing question: What are the symptoms of gout?\n",
      "2025-05-19 11:40:13,548 - __main__ - INFO - Got response: Question: What are the symptoms of gout? Answer: G...\n",
      "2025-05-19 11:40:13,548 - __main__ - INFO - Testing question: How is gout diagnosed?\n",
      "2025-05-19 11:40:15,049 - __main__ - INFO - Got response: Question: How is gout diagnosed? Answer: Gout is a...\n",
      "2025-05-19 11:40:15,050 - __main__ - INFO - Testing question: What treatments are available for gout?\n",
      "2025-05-19 11:40:16,466 - __main__ - INFO - Got response: Question: What treatments are available for gout?A...\n",
      "2025-05-19 11:40:16,466 - __main__ - INFO - Testing question: What lifestyle changes can help manage gout?\n",
      "2025-05-19 11:40:18,008 - __main__ - INFO - Got response: Question: What lifestyle changes can help manage g...\n",
      "2025-05-19 11:40:18,009 - __main__ - INFO - Testing question: What foods should be avoided with gout?\n",
      "2025-05-19 11:40:19,284 - __main__ - INFO - Got response: Question: What foods should be avoided with gout?A...\n",
      "2025-05-19 11:40:19,285 - __main__ - INFO - Testing contextual chat...\n",
      "2025-05-19 11:40:19,287 - __main__ - INFO - Testing contextual chat with 5 questions\n",
      "2025-05-19 11:40:19,287 - __main__ - INFO - Testing contextual question: What are the symptoms of gout?\n",
      "2025-05-19 11:40:20,768 - __main__ - INFO - Got response: Question: What are the symptoms of gout? Answer: G...\n",
      "2025-05-19 11:40:20,769 - __main__ - INFO - Testing contextual question: How is gout diagnosed?\n",
      "2025-05-19 11:40:22,170 - __main__ - INFO - Got response: Gout is a painful and painful condition. Symptoms ...\n",
      "2025-05-19 11:40:22,171 - __main__ - INFO - Testing contextual question: What treatments are available for gout?\n",
      "2025-05-19 11:40:24,447 - __main__ - INFO - Got response: Gout is a painful and painful condition. Symptoms ...\n",
      "2025-05-19 11:40:24,448 - __main__ - INFO - Testing contextual question: What lifestyle changes can help manage gout?\n",
      "2025-05-19 11:40:26,707 - __main__ - INFO - Got response: Gout is a painful and painful condition. Symptoms ...\n",
      "2025-05-19 11:40:26,708 - __main__ - INFO - Testing contextual question: What foods should be avoided with gout?\n",
      "2025-05-19 11:40:29,093 - __main__ - INFO - Got response: Gout is a painful and painful condition. Symptoms ...\n",
      "2025-05-19 11:40:29,095 - __main__ - INFO - Test results saved to results/part_2/example.txt\n",
      "2025-05-19 11:40:29,095 - __main__ - INFO - Testing complete!\n",
      "2025-05-19 11:40:29,096 - __main__ - INFO - Tested 5 questions\n",
      "2025-05-19 11:40:29,096 - __main__ - INFO - One-off chat responses: 5\n",
      "2025-05-19 11:40:29,096 - __main__ - INFO - Contextual chat responses: 5\n"
     ]
    }
   ],
   "source": [
    "# utils/test_chat.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    # Check if we're in a notebook\n",
    "    get_ipython\n",
    "    \n",
    "    # If we are, set the current directory manually\n",
    "    notebook_path = os.getcwd()\n",
    "    utils_dir = os.path.join(notebook_path, 'utils')\n",
    "    \n",
    "    # Make sure the utils directory exists\n",
    "    os.makedirs(utils_dir, exist_ok=True)\n",
    "    \n",
    "    # Add it to the path\n",
    "    if utils_dir not in sys.path:\n",
    "        sys.path.append(utils_dir)\n",
    "    \n",
    "    # Save the modules to files if they don't exist yet\n",
    "    one_off_path = os.path.join(utils_dir, 'one_off_chat.py')\n",
    "    conv_path = os.path.join(utils_dir, 'conversation.py')\n",
    "    \n",
    "    # Get our functions from the notebook environment\n",
    "    logger.info(\"Running in notebook mode, saving modules...\")\n",
    "    \n",
    "except NameError:\n",
    "    # We're running as a script\n",
    "    current_dir = Path(__file__).parent\n",
    "    sys.path.append(str(current_dir))\n",
    "\n",
    "# Import our chat modules\n",
    "try:\n",
    "    # Try importing as modules\n",
    "    try:\n",
    "        from one_off_chat import get_response as get_one_off_response\n",
    "        from conversation import get_response as get_contextual_response\n",
    "        logger.info(\"Successfully imported chat modules\")\n",
    "    except ImportError:\n",
    "        logger.info(\"Using functions from notebook environment\")\n",
    "        # We'll use the functions defined in previous cells\n",
    "        get_one_off_response = get_response  # from one-off chat cell\n",
    "        get_contextual_response = get_response  # from conversation.py cell\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to import chat modules: {e}\")\n",
    "    logger.error(\"Make sure to run the cells defining get_response functions first!\")\n",
    "    raise\n",
    "\n",
    "\n",
    "def test_one_off_chat(questions, model_name=\"facebook/bart-large-cnn\", api_key=None):\n",
    "    results = {}\n",
    "    \n",
    "    # Get API key from environment if not provided\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "        if not api_key:\n",
    "            logger.error(\"No API key provided and none found in environment\")\n",
    "            return {\"error\": \"API key is required but none was provided\"}\n",
    "\n",
    "    logger.info(f\"Testing one-off chat with {len(questions)} questions\")\n",
    "    \n",
    "    for question in questions:\n",
    "        logger.info(f\"Testing question: {question}\")\n",
    "        # Get response using the one-off chat function\n",
    "        response = get_one_off_response(question, model_name=model_name, api_key=api_key)\n",
    "        results[question] = response\n",
    "        logger.info(f\"Got response: {response[:50]}...\")  # Log first 50 chars\n",
    "        \n",
    "    return results\n",
    "\n",
    "def test_contextual_chat(questions, model_name=\"facebook/bart-large-cnn\", api_key=None):\n",
    "    results = []\n",
    "    history = []\n",
    "    \n",
    "    # Get API key from environment if not provided\n",
    "    if api_key is None:\n",
    "        api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "        if not api_key:\n",
    "            logger.error(\"No API key provided and none found in environment\")\n",
    "            return [(\"error\", \"API key is required but none was provided\")]\n",
    "    \n",
    "    logger.info(f\"Testing contextual chat with {len(questions)} questions\")\n",
    "    \n",
    "    for question in questions:\n",
    "        logger.info(f\"Testing contextual question: {question}\")\n",
    "        # Get response using the contextual chat function\n",
    "        response = get_contextual_response(\n",
    "            question, \n",
    "            history=history, \n",
    "            model_name=model_name, \n",
    "            api_key=api_key\n",
    "        )\n",
    "        results.append((question, response))\n",
    "        logger.info(f\"Got response: {response[:50]}...\")  # Log first 50 chars\n",
    "        \n",
    "        # Update history with the current exchange\n",
    "        history.append((question, response))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# List of healthcare questions to test\n",
    "test_questions = [\n",
    "    \"What are the symptoms of gout?\",\n",
    "    \"How is gout diagnosed?\",\n",
    "    \"What treatments are available for gout?\",\n",
    "    \"What lifestyle changes can help manage gout?\",\n",
    "    \"What foods should be avoided with gout?\"\n",
    "]\n",
    "\n",
    "def save_results(results, contextual_results=None, output_file=\"results/part_2/example.txt\"):\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write header\n",
    "        f.write(\"# LLM Chat Tool Test Results\\n\\n\")\n",
    "\n",
    "        # Add medical disclaimer\n",
    "        f.write(\"## IMPORTANT MEDICAL DISCLAIMER\\n\\n\")\n",
    "        f.write(\"**WARNING: The responses generated by this LLM are NOT medically accurate and should NOT be used for healthcare decisions.**\\n\\n\")\n",
    "        f.write(\"The facebook/bart-large-cnn model used was primarily trained to summarize news articles, not to provide medical advice. \")\n",
    "        f.write(\"The responses may contain incorrect and incomplete information about symptoms, diagnoses, and treatments. \")\n",
    "        f.write(\"Due to using a free language model, not all answers will be available from the website as it is a public site.\\n\\n\")\n",
    "        f.write(\"For this assignment, with the free Hugging Face API account, I was only able to get access to the bart-cnn model which is a low-quality language model.\\nThe more advanced models (flan-T5, gpt2, PubMedBERT, Bio_ClinicalBERT, etc.) were unable to be accessed (404 errors/permission denied) due to using the free account.\\n\\n\")\n",
    "\n",
    "        # Write usage examples\n",
    "        f.write(\"## Usage Examples\\n\\n\")\n",
    "        f.write(\"```bash\\n\")\n",
    "        f.write(\"# Run the one-off chat\\n\")\n",
    "        f.write(\"python utils/one_off_chat.py\\n\\n\")\n",
    "        f.write(\"# Run the contextual chat\\n\")\n",
    "        f.write(\"python utils/conversation.py\\n\")\n",
    "        f.write(\"```\\n\\n\")\n",
    "        \n",
    "        # Write test results for one-off chat\n",
    "        f.write(\"## One-Off Chat Test Results\\n\\n\")\n",
    "        f.write(\"```csv\\n\")\n",
    "        f.write(\"question,response\\n\")\n",
    "        \n",
    "        for question, response in results.items():\n",
    "            # Format the question and response for CSV\n",
    "            q = question.replace(',', '').replace('\\n', ' ')\n",
    "            r = str(response).replace(',', '').replace('\\n', ' ')\n",
    "            f.write(f\"{q},{r}\\n\")\n",
    "            \n",
    "        f.write(\"```\\n\\n\")\n",
    "        \n",
    "        # Write test results for contextual chat if provided\n",
    "        if contextual_results:\n",
    "            f.write(\"## Contextual Chat Test Results\\n\\n\")\n",
    "            f.write(\"```\\n\")\n",
    "            \n",
    "            # For each exchange, show the progression of the conversation\n",
    "            for i, (question, response) in enumerate(contextual_results):\n",
    "                f.write(f\"### Exchange {i+1}\\n\\n\")\n",
    "                f.write(f\"**Q:** {question}\\n\\n\")\n",
    "                f.write(f\"**A:** {response}\\n\\n\")\n",
    "                \n",
    "            f.write(\"```\\n\")\n",
    "\n",
    "# Run the test and save results\n",
    "def main():\n",
    "    # Get API key from environment\n",
    "    api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "    if not api_key:\n",
    "        logger.error(\"No API key found in environment variables.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    model_name = \"facebook/bart-large-cnn\"  # Use the model that works for you\n",
    "    \n",
    "    try:\n",
    "        # Test the one-off chat\n",
    "        logger.info(\"Testing one-off chat...\")\n",
    "        results = test_one_off_chat(test_questions, model_name, api_key)\n",
    "        \n",
    "        # Test the contextual chat\n",
    "        logger.info(\"Testing contextual chat...\")\n",
    "        contextual_results = test_contextual_chat(test_questions, model_name, api_key)\n",
    "        \n",
    "        # Save the results\n",
    "        save_results(results, contextual_results)\n",
    "        logger.info(f\"Test results saved to results/part_2/example.txt\")\n",
    "        \n",
    "        # Print summary\n",
    "        logger.info(\"Testing complete!\")\n",
    "        logger.info(f\"Tested {len(test_questions)} questions\")\n",
    "        logger.info(f\"One-off chat responses: {len(results)}\")\n",
    "        logger.info(f\"Contextual chat responses: {len(contextual_results)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during testing: {e}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc())\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e45bff",
   "metadata": {},
   "source": [
    "## Progress Checkpoints\n",
    "\n",
    "1. **API Connection**:\n",
    "   - [ ] Successfully connect to the Hugging Face API\n",
    "   - [ ] Send a query and receive a response\n",
    "   - [ ] Handle API errors gracefully\n",
    "\n",
    "2. **Chat Function Implementation**:\n",
    "   - [ ] Implement the get_response function\n",
    "   - [ ] Create the run_chat function for interactive sessions\n",
    "   - [ ] Handle errors and edge cases\n",
    "\n",
    "3. **Command Line Interface**:\n",
    "   - [ ] Create a parser with appropriate arguments\n",
    "   - [ ] Implement the main function\n",
    "   - [ ] Test the CLI functionality\n",
    "\n",
    "4. **Testing and Evaluation**:\n",
    "   - [ ] Test the functions with healthcare questions\n",
    "   - [ ] Save the results in a structured format\n",
    "   - [ ] Analyze the quality of responses\n",
    "\n",
    "## Common Issues and Solutions\n",
    "\n",
    "1. **API Access Issues**:\n",
    "   - Problem: Rate limiting\n",
    "   - Solution: Implement exponential backoff and retry logic\n",
    "   - Problem: Authentication errors\n",
    "   - Solution: Verify API key and environment variables\n",
    "\n",
    "2. **Response Parsing Issues**:\n",
    "   - Problem: Unexpected response format\n",
    "   - Solution: Add error handling for different response structures\n",
    "   - Problem: Empty or error responses\n",
    "   - Solution: Provide meaningful fallback responses\n",
    "\n",
    "3. **CLI Issues**:\n",
    "   - Problem: Arguments not parsed correctly\n",
    "   - Solution: Test with different argument combinations\n",
    "   - Problem: Script not executable\n",
    "   - Solution: Check file permissions\n",
    "\n",
    "## What to Submit\n",
    "\n",
    "1. Your implementation of the chat scripts:\n",
    "   - Basic requirement: `utils/one_off_chat.py` for single prompt/response chat\n",
    "   - Stretch goal (optional): `utils/conversation.py` for contextual chat\n",
    "   - Testing script: `utils/test_chat.py` to evaluate your implementation\n",
    "\n",
    "2. Test results in `results/part_2/example.txt` with the following format:\n",
    "   - Usage examples section showing how to run your scripts\n",
    "   - Test results section with CSV-formatted question/response pairs\n",
    "   - If you implemented the stretch goal, include examples of contextual exchanges\n",
    "\n",
    "The auto-grader should check:\n",
    "1. That your chat scripts can be executed\n",
    "2. That they correctly handle the test questions\n",
    "3. That your results file contains the required sections"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
